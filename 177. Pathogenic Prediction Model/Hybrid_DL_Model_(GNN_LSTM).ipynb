{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f035f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ebb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install torchsummary using pip\n",
    "#!pip install pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc88c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pytorch_lightning as pl  # For displaying the summary of a model\n",
    "\n",
    "from pyfaidx import Fasta\n",
    "from functools import lru_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eee112",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_filepath = \"/kaggle/input/mutation/Mutation_and_healthy_data.csv\"\n",
    "df = pd.read_csv(mut_filepath, low_memory=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd42d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chr'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e68bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ref'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f01e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_chroms = ['NW_015148969.2', 'NW_009646203.1', 'NW_009646206.1']\n",
    "df = df[~df['chr'].isin(out_chroms)]\n",
    "df = df.drop('variation_id', axis=1).dropna()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['alt'].apply(lambda var: len(var.split(\",\")) == 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.loc[[0, 10000, 16148, 1255788, 1145676]]\n",
    "temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ef147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['alt'].apply(lambda var: len(var.split(\",\")) == 1)].reset_index(drop=True)\n",
    "df['chr'] = df['chr'].replace({'MT': 'M'})\n",
    "df['chr'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e434062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[df['clinical_significance'] == 'non-harmful'].iloc[:207150]\n",
    "#df2 = df[df['clinical_significance'] == 'harmful'].iloc[:207150]\n",
    "#df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6815ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clinical_significance'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_path = \"/kaggle/input/mutation/hg38.fa\"\n",
    "#new_genome_path = \"/kaggle/working/hg38.fa\"\n",
    "#!cp $genome_path \"/kaggle/working/\"\n",
    "genome = Fasta(genome_path, rebuild=False)\n",
    "\n",
    "W = 10\n",
    "pos = 74484579 - 1\n",
    "genome['chr14'][pos-W : pos+W].seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a52383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract reference and mutated sequences\n",
    "def get_reference_and_mutated_sequence(chrom, pos, ref, alt, window=10):\n",
    "    \"\"\"\n",
    "    Extracts the reference and mutated sequences from the genome around the mutation.\n",
    "    chr: Chromosome (as string, e.g., '1')\n",
    "    pos: Position (1-based position of the mutation)\n",
    "    ref: Reference allele\n",
    "    alt: Alternate alleles (comma-separated if multiple)\n",
    "    window: Number of base pairs before and after the mutation position to extract\n",
    "    \"\"\"\n",
    "    # Adjust for 0-based indexing\n",
    "    pos = int(pos) - 1\n",
    "    \n",
    "    # Extract reference sequence around the mutation (Â± window)\n",
    "    ref_seq = genome[chrom][pos-window:pos+window+1].seq\n",
    "    \n",
    "    # Mutated sequences (could be multiple if multiple alternate alleles)\n",
    "    alt_alleles = alt.split(',')\n",
    "    mutated_seqs = []\n",
    "    for alt_allele in alt_alleles:\n",
    "        mutated_seq = ref_seq[:window] + alt_allele + ref_seq[window+1:]\n",
    "        mutated_seqs.append(mutated_seq)\n",
    "\n",
    "    return ref_seq, mutated_seqs\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    one_hot_seq = [mapping.get(base, [0, 0, 0, 0]) for base in sequence]\n",
    "    return torch.tensor(one_hot_seq)\n",
    "\n",
    "chrom, pos, ref, alt = 'chr11', 6391633, 'C', '-,CC,CCAACCCCCC'\n",
    "\n",
    "# Extract reference and mutated sequences from hg38 genome\n",
    "ref_seq, mutated_seqs = get_reference_and_mutated_sequence(chrom, pos, ref, alt)\n",
    "print(mutated_seqs)\n",
    "\n",
    "# Convert reference and mutated sequences to one-hot encoded format\n",
    "ref_one_hot = one_hot_encode(ref_seq)\n",
    "mut_one_hots = [one_hot_encode(mut_seq) for mut_seq in mutated_seqs]\n",
    "\n",
    "print(\"One-Hot Encoded Reference Sequence:\", ref_one_hot)\n",
    "for i, mut_one_hot in enumerate(mut_one_hots):\n",
    "    print(f\"One-Hot Encoded Mutated Sequence {i+1}:\", mut_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2048)\n",
    "def get_sequence(chrom, start, end):\n",
    "    return str(genome[f\"chr{chrom}\"][start:end])\n",
    "\n",
    "def process_mutations_for_lstm(df, window=10):\n",
    "    # Extract sequences\n",
    "    df['start'] = df['pos'] - window - 1\n",
    "    df['end'] = df['pos'] + window\n",
    "    df['ref_seq'] = df.apply(lambda row: get_sequence(row['chr'], row['start'], row['end']), axis=1)\n",
    "    \n",
    "    # Generate mutated sequences\n",
    "    def generate_mut_seqs(row):\n",
    "        ref_seq = row['ref_seq']\n",
    "        alt_alleles = row['alt'].split(',')\n",
    "        return [ref_seq[:window] + alt + ref_seq[window+len(row['ref']):] for alt in alt_alleles]\n",
    "    \n",
    "    df['mut_seqs'] = df.apply(generate_mut_seqs, axis=1)\n",
    "    \n",
    "    # Separate reference and mutated sequences\n",
    "    ref_seqs = df['ref_seq'].tolist()\n",
    "    mut_seqs = [seq for seqs in df['mut_seqs'] for seq in seqs]\n",
    "    \n",
    "    # One-hot encode all sequences\n",
    "    ref_encoded = one_hot_encode_vectorized(ref_seqs)\n",
    "    mut_encoded = one_hot_encode_vectorized(mut_seqs)\n",
    "    \n",
    "    return ref_encoded, mut_encoded\n",
    "\n",
    "def one_hot_encode_vectorized(sequences):\n",
    "    char_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    seq_array = np.array([list(seq.ljust(max_len, 'N')) for seq in sequences])\n",
    "    one_hot = np.zeros((len(sequences), max_len, 4), dtype=np.float32)\n",
    "    for char, index in char_to_int.items():\n",
    "        one_hot[seq_array == char, index] = 1\n",
    "    return torch.from_numpy(one_hot)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Process mutations\n",
    "    ref_encoded, mut_encoded = process_mutations_for_lstm(df)\n",
    "    print(f\"Reference shape: {ref_encoded.shape}, Mutated shape: {mut_encoded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f50864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'chr' and 'variation_id' column\n",
    "#variation_id_encoder = []\n",
    "#for i, vid in enumerate(df['variation_id']):\n",
    "#    if str(vid) == '0':\n",
    "#        variation_id_encoder.append(0)\n",
    "#    else:\n",
    "#        variation_id_encoder.append(i + 1)\n",
    "#print(variation_id_encoder)\n",
    "\n",
    "#df.loc[:, 'variation_id_encoded'] = variation_id_encoder\n",
    "#df['variation_id'] = df['variation_id'].astype(int)\n",
    "df['chr_encoded'] = df['chr'].replace({'X' : 23, 'Y' : 24, 'M' : 25, 'NW_009646206.1' : 26,\n",
    "            'NW_009646201.1' : 27, 'NW_009646203.1' : 28, 'NW_015148969.2': 29}).astype(int)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoders\n",
    "gene_encoder = LabelEncoder()\n",
    "ref_encoder = LabelEncoder()\n",
    "alt_encoder = LabelEncoder()\n",
    "#variation_encoder = LabelEncoder()\n",
    "variant_type_encoder = LabelEncoder()\n",
    "clinical_significance_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "df['gene_encoded'] = gene_encoder.fit_transform(df['gene'])\n",
    "df['ref_encoded'] = ref_encoder.fit_transform(df['ref'])\n",
    "df['alt_encoded'] = alt_encoder.fit_transform(df['alt'])\n",
    "#df['variation'] = variation_encoder.fit_transform(df['variation'])\n",
    "df['variant_type_encoded'] = variant_type_encoder.fit_transform(df['variant_type'])\n",
    "df['clinical_significance_encoded'] = clinical_significance_encoder.fit_transform(df['clinical_significance'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "data = df.iloc[:50]\n",
    "\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Step 1: Add nodes to the graph\n",
    "# Each node is identified by variation_id and has attributes like gene, chr, pos, etc.\n",
    "for i, row in data.iterrows():\n",
    "    G.add_node(row['variation_id'], gene=row['gene'], chr=row['chr'], pos=row['pos'],\n",
    "               ref=row['ref'], alt=row['alt'], variant_type=row['variant_type'],\n",
    "               clinical_significance=row['clinical_significance'])\n",
    "\n",
    "# Step 2: Add edges based on the combined criteria\n",
    "# Define a proximity threshold (e.g., 100 kb)\n",
    "threshold = 100000  # 100 kb threshold\n",
    "\n",
    "# Iterate through the dataset and construct edges\n",
    "for i, row in data.iterrows():\n",
    "    alt_alleles = set(row['alt'].split(','))\n",
    "    genes = set(row['gene'].split(';'))  # Split multiple genes if present\n",
    "    for j, other_row in data.iterrows():\n",
    "        other_alt_alleles = set(other_row['alt'].split(','))\n",
    "        other_genes = set(other_row['gene'].split(';'))\n",
    "\n",
    "        # Check clinical significance, shared alternate alleles, shared genes, and proximity\n",
    "        if (i != j and\n",
    "            row['clinical_significance'] == other_row['clinical_significance'] and  # Same clinical significance\n",
    "            len(alt_alleles & other_alt_alleles) > 0 and  # Shared alternate alleles\n",
    "            len(genes & other_genes) > 0 and  # Shared genes\n",
    "            row['chr'] == other_row['chr'] and  # Same chromosome\n",
    "            abs(row['pos'] - other_row['pos']) < threshold):  # Proximity threshold\n",
    "\n",
    "            # Add edge if all conditions are met\n",
    "            G.add_edge(row['variation_id'], other_row['variation_id'])\n",
    "\n",
    "# Step 3: Check the graph (optional)\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your pandas DataFrame\n",
    "def create_graph(df):\n",
    "    # Create node features more efficiently\n",
    "    feature_columns = ['gene_encoded', 'chr_encoded', 'pos', 'ref_encoded', 'alt_encoded', 'variant_type_encoded']\n",
    "    node_features = torch.tensor(df[feature_columns].values, dtype=torch.float)\n",
    "\n",
    "    # Encode clinical significance\n",
    "    node_labels = torch.tensor(df['clinical_significance_encoded'].values, dtype=torch.long)\n",
    "\n",
    "    # Create edges more efficiently\n",
    "    gene_groups = df.groupby('gene').groups\n",
    "    edges = []\n",
    "    for indices in gene_groups.values():\n",
    "        indices = sorted(indices)\n",
    "        edges.extend(zip(indices[:-1], indices[1:]))\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create the PyTorch Geometric Data object\n",
    "    graph_data = Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
    "\n",
    "    return graph_data\n",
    "\n",
    "# Usage\n",
    "graph_data = create_graph(df)\n",
    "\n",
    "# Check the prepared data\n",
    "print(\"Node Features shape:\", graph_data.x.shape)\n",
    "print(\"Edge Index shape:\", graph_data.edge_index.shape)\n",
    "print(\"Node Labels shape:\", graph_data.y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5f1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5998ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_graph(graph_data):\n",
    "    # Create a NetworkX graph from the PyTorch Geometric Data object\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes with features as attributes\n",
    "    for i in range(graph_data.x.size(0)):\n",
    "        G.add_node(i, features=graph_data.x[i].numpy(), label=graph_data.y[i].item())\n",
    "\n",
    "    # Add edges\n",
    "    edge_index = graph_data.edge_index.numpy()\n",
    "    print(edge_index)\n",
    "    G.add_edges_from(zip(edge_index[0], edge_index[1]))\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)  # positions for all nodes\n",
    "    node_labels = {i: G.nodes[i]['label'] for i in G.nodes}  # Extract labels\n",
    "    node_colors = [G.nodes[i]['label'] for i in G.nodes]  # Optional: use labels for colors\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw(G, pos, with_labels=True, labels=node_labels, node_color=node_colors, cmap=plt.cm.viridis, node_size=500, font_size=10)\n",
    "    plt.title('Graph Visualization')\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "#visualize_graph(graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd6233-61a5-46db-a6ac-178934ecb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Efficient_GCN_LSTM_Dataset(Dataset):\n",
    "    def __init__(self, graph_data, ref_encoded, mut_encoded):\n",
    "        self.x = graph_data.x\n",
    "        self.edge_index = graph_data.edge_index\n",
    "        self.y = graph_data.y\n",
    "        self.ref_seq = ref_encoded\n",
    "        self.mut_seq = mut_encoded\n",
    "        self.num_nodes = graph_data.x.shape[0]  # Total number of nodes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]  # Number of graphs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.num_nodes\n",
    "        end_idx = (idx + 1) * self.num_nodes\n",
    "        return Data(\n",
    "            x=self.x[start_idx:end_idx],\n",
    "            edge_index=self.edge_index - start_idx,  # Adjust edge_index for this graph\n",
    "            y=self.y[idx],\n",
    "            ref_seq=self.ref_seq[idx],\n",
    "            mut_seq=self.mut_seq[idx],\n",
    "            num_nodes=self.num_nodes\n",
    "        )\n",
    "\n",
    "def custom_collate(batch):\n",
    "    data_list = [item for item in batch]\n",
    "    batched_data = Batch.from_data_list(data_list)\n",
    "    \n",
    "    # Adjust edge_index for the batched graph\n",
    "    cumsum_nodes = torch.cat([data.num_nodes.new_zeros(1), data.num_nodes.cumsum(dim=0)[:-1]])\n",
    "    batched_data.edge_index += cumsum_nodes[batched_data.batch][batched_data.edge_index[0]]\n",
    "    \n",
    "    return batched_data\n",
    "\n",
    "dataset = Efficient_GCN_LSTM_Dataset(graph_data, ref_encoded, mut_encoded)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a3cee-ce62-4725-b981-105626a5b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_LSTM_Hybrid(nn.Module):\n",
    "    def __init__(self, num_node_features, gcn_hidden_channels, lstm_hidden_size, lstm_num_layers, seq_length):\n",
    "        super(GCN_LSTM_Hybrid, self).__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(num_node_features, gcn_hidden_channels)\n",
    "        self.conv2 = GCNConv(gcn_hidden_channels, gcn_hidden_channels)\n",
    "        \n",
    "        # LSTM layers for reference and mutated sequences\n",
    "        self.lstm_ref = nn.LSTM(1, lstm_hidden_size, num_layers=lstm_num_layers, batch_first=True)\n",
    "        self.lstm_mut = nn.LSTM(1, lstm_hidden_size, num_layers=lstm_num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(gcn_hidden_channels + 2 * lstm_hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Binary classification\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        ref_seq, mut_seq = data.ref_seq, data.mut_seq\n",
    "\n",
    "        # GCN forward pass\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # LSTM forward pass for ref sequence\n",
    "        _, (h_ref, _) = self.lstm_ref(ref_seq.unsqueeze(2).float())\n",
    "        ref_out = h_ref[-1]\n",
    "\n",
    "        # LSTM forward pass for mut sequence\n",
    "        _, (h_mut, _) = self.lstm_mut(mut_seq.unsqueeze(2).float())\n",
    "        mut_out = h_mut[-1]\n",
    "\n",
    "        # Combine GCN and LSTM outputs\n",
    "        combined = torch.cat([x, ref_out, mut_out], dim=-1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        out = F.relu(self.fc1(combined))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model initialization\n",
    "num_node_features = 6  # As per your Node Features shape\n",
    "gcn_hidden_channels = 32\n",
    "lstm_hidden_size = 64\n",
    "lstm_num_layers = 2\n",
    "seq_length = dataset.ref_seq.shape[1]  # Assuming ref_seq and mut_seq have the same length\n",
    "\n",
    "model = GCN_LSTM_Hybrid(num_node_features, gcn_hidden_channels, lstm_hidden_size, lstm_num_layers, seq_length).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39871c-8a9a-4a87-8bda-ed277a7b5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        # Move the entire batch to the device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(out.squeeze(), batch.y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807d1e5-16a3-4670-b12f-5c8701748e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch in loader:\n",
    "        # Move the entire batch to the device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(batch)\n",
    "\n",
    "        # Apply threshold for binary classification\n",
    "        pred = (out.squeeze() > 0.5).float()\n",
    "\n",
    "        # Calculate number of correct predictions\n",
    "        total_correct += int((pred == batch.y).sum())\n",
    "        total_samples += batch.num_graphs\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997cdfd-f02a-4894-8138-ac07b707be67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5889449,
     "sourceId": 9666052,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
