{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762f4cd-2968-4c4e-865d-a65ba768f2ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # arithmetic operations\n",
    "import pandas as pd  # handling dataframes\n",
    "from Bio.Seq import translate  # protein translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6479ee7-6ae4-492e-9880-20441109d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_reading_frame(row, mut_seq):\n",
    "    \"\"\"\n",
    "    Adjusts the reading frame of a given sequence based on a mutation sequence.\n",
    "\n",
    "    Parameters:\n",
    "    row (str): The sequence to be adjusted.\n",
    "    mut_seq (str): The mutation sequence containing fragments separated by 'NNK'.\n",
    "\n",
    "    Returns:\n",
    "    str: The adjusted sequence if a unique reading frame is found, None if no frame is found.\n",
    "    \n",
    "    Raises:\n",
    "    Exception: If multiple possible reading frames are found.\n",
    "    \"\"\"\n",
    "    # Split the mut_seq into fragments separated by 'NNK'\n",
    "    fragments = mut_seq.split('NNK')\n",
    "    \n",
    "    # Initialize list to store possible indices\n",
    "    possible_indices = []\n",
    "    \n",
    "    # Initialize the current length of matched sequence\n",
    "    length = 0\n",
    "    \n",
    "    for fragment in fragments:\n",
    "        # Skip empty fragments\n",
    "        if not fragment:\n",
    "            length += 3  # Move length forward by 3 for each 'NNK'\n",
    "            continue\n",
    "\n",
    "        # Find all occurrences of the fragment in the row\n",
    "        temp_indices = []\n",
    "        start = 0\n",
    "        while True:\n",
    "            index = row.find(fragment, start)\n",
    "            if index == -1:\n",
    "                break\n",
    "            temp_indices.append(index - length)\n",
    "            start = index + 3  # Move start forward by 3 for each 'NNK'\n",
    "\n",
    "        if not possible_indices:\n",
    "            possible_indices = temp_indices\n",
    "        else:\n",
    "            possible_indices = [idx for idx in possible_indices if idx in temp_indices]\n",
    "        \n",
    "        length += len(fragment) + 3  # Update length to include fragment and 'NNK'\n",
    "\n",
    "    if len(possible_indices) == 1:\n",
    "        index = possible_indices[0]\n",
    "        return row[index : index + len(mut_seq)]\n",
    "    elif len(possible_indices) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        raise Exception('Enter longer sequence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102cad74-7818-4336-abb5-1129d862a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_mutations(row, mut_seq):\n",
    "    \"\"\"\n",
    "    Translates mutations in a given sequence based on a mutation sequence.\n",
    "\n",
    "    Parameters:\n",
    "    row (str): The sequence to be translated.\n",
    "    mut_seq (str): The mutation sequence containing fragments separated by 'NNK'.\n",
    "\n",
    "    Returns:\n",
    "    str: The translated mutation sequence, or 'bad sequencing' if the input sequence is invalid.\n",
    "    \"\"\"\n",
    "    if not row:\n",
    "        return 'bad sequencing'\n",
    "    \n",
    "    split_seq = mut_seq.split('NNK')\n",
    "    length = 0\n",
    "    nnk_translation = \"\"\n",
    "    \n",
    "    for fragment in split_seq[:-1]:\n",
    "        length += len(fragment)\n",
    "        codon = row[length:length+3]\n",
    "        if codon:\n",
    "            nnk_translation += translate(codon)\n",
    "        length += 3\n",
    "    \n",
    "    return nnk_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06aeac41-a024-4f30-822b-7924fb74c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_recording_frame(row, rec_seq):\n",
    "    \"\"\"\n",
    "    Finds the recording frame of a given sequence based on a recording region sequence.\n",
    "\n",
    "    Parameters:\n",
    "    row (str): The sequence to be examined.\n",
    "    rec_seq (str): The recording region sequence containing fragments separated by 'C'.\n",
    "\n",
    "    Returns:\n",
    "    str: The substring of `row` that matches the recording region sequence if a unique match is found, None if no match is found.\n",
    "    \n",
    "    Raises:\n",
    "    Exception: If multiple possible recording frames are found.\n",
    "    \"\"\"\n",
    "    # Split rec_seq into fragments separated by 'C'\n",
    "    fragments = rec_seq.split('C')\n",
    "    \n",
    "    # Calculate the constant number of 'C's and 'T's in the recording region\n",
    "    num_CT = len(fragments) + rec_seq.count('T') - 1\n",
    "    \n",
    "    # Initialize list to store possible indices\n",
    "    possible_indices = []\n",
    "    \n",
    "    # Initialize the current length of matched sequence\n",
    "    length = 0\n",
    "    \n",
    "    for fragment in fragments:\n",
    "        # Skip empty fragments\n",
    "        if not fragment:\n",
    "            length += 1  # Move length forward by 1 for each 'C'\n",
    "            continue\n",
    "        \n",
    "        # Find all occurrences of the fragment in the row\n",
    "        temp_indices = []\n",
    "        start = 0\n",
    "        while True:\n",
    "            index = row.find(fragment, start)\n",
    "            if index == -1:\n",
    "                break\n",
    "            temp_indices.append(index - length)\n",
    "            start = index + len(fragment)  # Move start forward by the length of the fragment\n",
    "        \n",
    "        if not possible_indices:\n",
    "            possible_indices = temp_indices\n",
    "        else:\n",
    "            possible_indices = [idx for idx in possible_indices if idx in temp_indices]\n",
    "        \n",
    "        length += len(fragment) + 1  # Update length to include fragment and 'C'\n",
    "\n",
    "    # Remove indices that do not have the correct number of 'C's and 'T's\n",
    "    possible_indices = [idx for idx in possible_indices if \n",
    "                        row[idx:idx + len(rec_seq)].count('C') + row[idx:idx + len(rec_seq)].count('T') == num_CT]\n",
    "\n",
    "    if len(possible_indices) == 1:\n",
    "        index = possible_indices[0]\n",
    "        return row[index : index + len(rec_seq)]\n",
    "    elif len(possible_indices) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        raise Exception('Enter longer sequence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4fd45e-86f5-47b1-a632-e778870ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(df, filename, targetSeq, recording='CCACCCGCaaaa'):\n",
    "    \"\"\"\n",
    "    Processes mutation data and records it to CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the output CSV file.\n",
    "    targetSeq (str): The target sequence to process.\n",
    "    recording (str, optional): The recording region sequence. Default is 'CCACCCGCaaaa'.\n",
    "    \"\"\"\n",
    "    mutStrand = targetSeq.upper()\n",
    "    \n",
    "    # Remove dashes and convert to uppercase\n",
    "    df.loc[:, 'FixedSequence'] = df['TargetSequence'].apply(lambda seq: seq.replace(\"-\", \"\").upper())\n",
    "    # Adjust the reading frame according to the mutation strand\n",
    "    df.loc[:, 'Mutation Reading Frame'] = df['FixedSequence'].apply(lambda x: adjust_reading_frame(x, mutStrand))\n",
    "    # Translate mutations based on the reading frame and mutation strand\n",
    "    df.loc[:, 'Mutations'] = df['Mutation Reading Frame'].apply(lambda x: translate_mutations(x, mutStrand))\n",
    "\n",
    "    recRegion = recording.upper()\n",
    "    # Find the recording frame within the fixed sequence\n",
    "    df.loc[:, 'Recording'] = df['FixedSequence'].apply(lambda x: find_recording_frame(x, recRegion))\n",
    "\n",
    "    # Select relevant columns for mutation and recording\n",
    "    df_mut_rec = df[['TargetSequence', 'Mutations', 'Recording', 'Reads', 'Type']]\n",
    "    df_mut_rec.to_csv('2NNK_Mut_Rec_1.csv')\n",
    "\n",
    "    # Filter sequences marked as 'bad sequencing'\n",
    "    df_bad_seq = df[df['Mutations'] == 'bad sequencing']\n",
    "    df_bad_seq.to_csv('2NNK_bad_1.csv')\n",
    "\n",
    "    # Group data by mutations and sum the reads\n",
    "    df0 = df[['Mutations', 'Recording', 'Reads']]\n",
    "    grouped_df = df0.groupby('Mutations')['Reads'].sum().reset_index()\n",
    "    grouped_df.rename(columns={'Reads': 'Reads sum'}, inplace=True)\n",
    "\n",
    "    # Filter out 'bad sequencing', matching recording regions, and NaN recordings\n",
    "    df1 = df0[(df['Mutations'] != 'bad sequencing') & (df['Recording'] != recRegion) & df['Recording'].notna()]\n",
    "\n",
    "    # Calculate T count and its squared value in the recording sequence\n",
    "    df1 = df1.assign(T_count=df1['Recording'].apply(lambda seq: seq.count(\"T\")),\n",
    "                     T_squared=lambda x: x['T_count'] ** 2,\n",
    "                     T_total=lambda x: x['T_count'] * x['Reads'],\n",
    "                     T_squared_tot=lambda x: x['T_squared'] * x['Reads'])\n",
    "\n",
    "    # Group by mutations and calculate sum of T_total and T_squared_total\n",
    "    grouped_df_T = df1.groupby('Mutations')['T_total'].sum().reset_index()\n",
    "    grouped_df_T.rename(columns={'T_total': 'T_sum'}, inplace=True)\n",
    "    grouped_df_T2 = df1.groupby('Mutations')['T_squared_tot'].sum().reset_index()\n",
    "    grouped_df_T2.rename(columns={'T_squared_tot': 'T^2_sum'}, inplace=True)\n",
    "    grouped_df_edit = df1.groupby('Mutations')['Reads'].sum().reset_index()\n",
    "    grouped_df_edit.rename(columns={'Reads': 'Edit reads'}, inplace=True)\n",
    "    \n",
    "    # Merge grouped data into a single DataFrame\n",
    "    merged = pd.merge(grouped_df_edit, grouped_df_T, on='Mutations', how='left')\n",
    "    merged = pd.merge(merged, grouped_df_T2, on='Mutations', how='left')\n",
    "    merged = pd.merge(grouped_df, merged, on='Mutations', how='left')\n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    merged.to_csv(filename)\n",
    "    \n",
    "    # Print the DataFrames for inspection\n",
    "    print(\"Part of 2NNK_Mut_Rec.csv:\")\n",
    "    print(df_mut_rec.head())\n",
    "    print(\"\\nPart of 2NNK_bad.csv:\")\n",
    "    print(df_bad_seq.head())\n",
    "    print(f\"\\nPart of {filename}:\")\n",
    "    print(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550bb64f-108f-4c88-9c9b-9fcf6673d968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of 2NNK_Mut_Rec.csv:\n",
      "                                      TargetSequence Mutations     Recording  \\\n",
      "0  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...        VI  TTATTTGCAAAA   \n",
      "1  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...        VI  CCACCCGCAAAA   \n",
      "2  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...        VI  TTATTCGCAAAA   \n",
      "3  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGcgGTG--G...        RW  TTATTCGCAAAA   \n",
      "4  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...        VI  CCATTCGCAAAA   \n",
      "\n",
      "   Reads                    Type  \n",
      "0     37          5 Base Changes  \n",
      "1     33                      WT  \n",
      "2     26          4 Base Changes  \n",
      "3     20  Insertion and Deletion  \n",
      "4     19          2 Base Changes  \n",
      "\n",
      "Part of 2NNK_bad.csv:\n",
      "                                         TargetSequence  Reads  AvgQScore  \\\n",
      "675   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGCAG-TTGg...      5         32   \n",
      "775   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGG-----GG...      5         32   \n",
      "954   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAgaGAGGCGATG...      4         32   \n",
      "1218  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGTAGA-TGG...      4         32   \n",
      "1320  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGA-GTTATGGG...      3         33   \n",
      "\n",
      "                        Type   Pct  IndelLength TargetAA ReferenceAA  \\\n",
      "675   Insertion and Deletion  0.03            2    IEVF*       IEVF*   \n",
      "775                 Deletion  0.03           -5    IEVF*       IEVF*   \n",
      "954                Insertion  0.02            2    IEVF*       IEVF*   \n",
      "1218                Deletion  0.02           -1    IEVF*       IEVF*   \n",
      "1320                Deletion  0.02           -1    IEVF*       IEVF*   \n",
      "\n",
      "                                          WideTargetSeq  \\\n",
      "675   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGCAG-TTGG...   \n",
      "775   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGG-----GG...   \n",
      "954   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGAGGCGATG...   \n",
      "1218  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGTAGA-TGG...   \n",
      "1320  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGA-GTTATGGG...   \n",
      "\n",
      "                                          WideReference TargetLeftFlank  \\\n",
      "675   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...                   \n",
      "775   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...                   \n",
      "954   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...                   \n",
      "1218  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...                   \n",
      "1320  ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGTGATTGG...                   \n",
      "\n",
      "     TargetRightFlank                                      FixedSequence  \\\n",
      "675                    ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGCAGTTGGG...   \n",
      "775                    ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGGGGCAACA...   \n",
      "954                    ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGAGGCGATG...   \n",
      "1218                   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGTAGATGGC...   \n",
      "1320                   ATAGAAGTATTTTAATGCTTCCCGAAGAAGTCGAAGAGTTATGGGC...   \n",
      "\n",
      "     Mutation Reading Frame       Mutations     Recording  \n",
      "675                    None  bad sequencing  CCACCCGCAAAA  \n",
      "775                    None  bad sequencing  CCACCCGCAAAA  \n",
      "954                    None  bad sequencing  TTATTTGCAAAA  \n",
      "1218                   None  bad sequencing  CCACCCGCAAAA  \n",
      "1320                   None  bad sequencing  CCACCCGCAAAA  \n",
      "\n",
      "Part of 2NNK_summary_1.csv:\n",
      "  Mutations  Reads sum  Edit reads  T_sum  T^2_sum\n",
      "0        **         14         7.0   21.0     79.0\n",
      "1        *A         41        22.0   85.0    347.0\n",
      "2        *C          9         5.0   16.0     58.0\n",
      "3        *D         10         2.0   10.0     50.0\n",
      "4        *E          6         5.0   19.0     83.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if file format is '.xlsx'\n",
    "input_filename = 'Plate1_abundance.xlsx'\n",
    "file_obj = pd.ExcelFile(input_filename)\n",
    "df = pd.read_excel(file_obj, 'Sheet1', keep_default_na=False, na_values=['_'])\n",
    "\n",
    "# if file format is '.csv'\n",
    "#df = pd.read_csv(\"data/4NNK.csv\")\n",
    "\n",
    "# Execute the main function\n",
    "output_filename = '2NNK_summary_1.csv'\n",
    "target_seq = 'gtcgaagagNNKNNKggcaacaaac'\n",
    "main(df, output_filename, target_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa280af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.testing as pdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e8dbff-8e64-4382-afa4-59193aef35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrames are equal.\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.read_csv('2NNK_summary.csv')\n",
    "table2 = pd.read_csv('2NNK_summary_1.csv')\n",
    "\n",
    "try:\n",
    "    pdt.assert_frame_equal(table1, table2)\n",
    "    print(\"The DataFrames are equal.\")\n",
    "except AssertionError as e:\n",
    "    print(\"The DataFrames are not equal:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666726b3-25d3-4e0d-8ac8-cadf8235b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrames are equal.\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.read_csv('2NNK_Mut_Rec.csv')\n",
    "table2 = pd.read_csv('2NNK_Mut_Rec_1.csv')\n",
    "\n",
    "try:\n",
    "    pdt.assert_frame_equal(table1, table2)\n",
    "    print(\"The DataFrames are equal.\")\n",
    "except AssertionError as e:\n",
    "    print(\"The DataFrames are not equal:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d321c0ac-30c3-4fdf-8c9f-3780f502701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrames are equal.\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.read_csv('2NNK_bad.csv')\n",
    "table2 = pd.read_csv('2NNK_bad_1.csv')\n",
    "\n",
    "try:\n",
    "    pdt.assert_frame_equal(table1, table2)\n",
    "    print(\"The DataFrames are equal.\")\n",
    "except AssertionError as e:\n",
    "    print(\"The DataFrames are not equal:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb390b-e640-4491-969e-66777b3e94f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
